// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: speech-to-text.proto

package ai.vernacular.speech;

public interface StreamingRecognizeRequestOrBuilder extends
    // @@protoc_insertion_point(interface_extends:speech_to_text.StreamingRecognizeRequest)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the
   * request. The first `StreamingRecognizeRequest` message must contain a
   * `streaming_config`  message.
   * </pre>
   *
   * <code>.speech_to_text.StreamingRecognitionConfig streaming_config = 1;</code>
   * @return Whether the streamingConfig field is set.
   */
  boolean hasStreamingConfig();
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the
   * request. The first `StreamingRecognizeRequest` message must contain a
   * `streaming_config`  message.
   * </pre>
   *
   * <code>.speech_to_text.StreamingRecognitionConfig streaming_config = 1;</code>
   * @return The streamingConfig.
   */
  ai.vernacular.speech.StreamingRecognitionConfig getStreamingConfig();
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the
   * request. The first `StreamingRecognizeRequest` message must contain a
   * `streaming_config`  message.
   * </pre>
   *
   * <code>.speech_to_text.StreamingRecognitionConfig streaming_config = 1;</code>
   */
  ai.vernacular.speech.StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder();

  /**
   * <pre>
   * The audio data to be recognized.
   * </pre>
   *
   * <code>bytes audio_content = 2;</code>
   * @return The audioContent.
   */
  com.google.protobuf.ByteString getAudioContent();

  public ai.vernacular.speech.StreamingRecognizeRequest.StreamingRequestCase getStreamingRequestCase();
}
